{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore');\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate Dataset for test purposes.",
    "# os.chdir(\"C:/Users/Hilak/Desktop/INTERESTS/Machine Learning A-Z Template Folder/Part 3 - Classification/Section 14 - Logistic Regression\");\n",
    "training_set = pd.read_csv(\"Social_Network_Ads.csv\");\n",
    "X = training_set.iloc[:, 1:4].values\n",
    "y = training_set.iloc[:, 4].values\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "le_x = LabelEncoder()\n",
    "X[:,0] = le_x.fit_transform(X[:,0])\n",
    "ohe = OneHotEncoder(categorical_features = [0])\n",
    "X = ohe.fit_transform(X).toarray()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "X[:,2:4] = ss.fit_transform(X[:, 2:4])\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(\"C:\\\\Users\\\\Hilak\\\\Desktop\\\\INTERESTS\\\\Machine Learning A-Z Template Folder\\\\Part 8 - Deep Learning\\\\Section 39 - Artificial Neural Networks (ANN)\");\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values\n",
    "\n",
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:]\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "X_test, X_CV, y_test, y_CV = train_test_split(X, y, test_size = 0.5)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T\n",
    "X_CV = X_CV.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z) : \n",
    "    return 1./(1 + np.exp(-z))\n",
    "def sigmoid_prime(z) :\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "def ReLU(z) : \n",
    "    return (z*(z > 0))\n",
    "def ReLU_prime(z) :\n",
    "    return 1*(z>=0)\n",
    "def lReLU(z) : \n",
    "    return np.maximum(z/100,z)\n",
    "def lReLU_prime(z) :\n",
    "    z = 1*(z>=0)\n",
    "    z[z==0] = 1/100\n",
    "    return z\n",
    "def tanh(z) : \n",
    "    return np.tanh(z)\n",
    "def tanh_prime(z) : \n",
    "    return (1-tanh(z)**2)\n",
    "\n",
    "class NeuralNet : \n",
    "    def __init__(self, layers, X, y, ac_func='sigmoid', init_method='gaussian', loss_func='b_ce', W=np.array([]), B=np.array([])) : \n",
    "        self.layers = layers\n",
    "        self.W = None\n",
    "        self.B = None\n",
    "        self.m = X.shape[1]\n",
    "        self.n = [X.shape[0], *layers]\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.cost = []\n",
    "        self.acc = 0\n",
    "        self.ac_func = ac_func\n",
    "        self.loss = loss_func\n",
    "        if len(W) and len(B) :\n",
    "            self.W = W\n",
    "            self.B = B\n",
    "        else : \n",
    "            if init_method=='gaussian': \n",
    "                self.W = [np.random.randn(self.n[nl], self.n[nl-1]) for nl in range(1,len(self.n))]\n",
    "                self.B = [np.random.randn(nl,1) for nl in self.layers]\n",
    "            elif init_method == 'random':\n",
    "                self.W = [np.random.rand(self.n[nl], self.n[nl-1]) for nl in range(1,len(self.n))]\n",
    "                self.B = [np.random.rand(nl,1) for nl in self.layers]\n",
    "            elif init_method == 'zeros':\n",
    "                self.W = [np.zeros((self.n[nl], self.n[nl-1]), 'float32') for nl in range(1,len(self.n))]\n",
    "                self.B = [np.zeros((nl,1), 'float32') for nl in self.layers]\n",
    "    \n",
    "    def startTraining(self, epochs, alpha, interval=100):\n",
    "        start = time.time()\n",
    "        for i in range(epochs+1) : \n",
    "            z,a = self._feedForward()\n",
    "            delta = self._cost_derivative(a[-1])\n",
    "            for l in range(1,len(z)) : \n",
    "                delta_w = np.dot(delta, a[-l-1].T)\n",
    "                delta_b = np.dot(delta, np.ones((self.m,1), 'int32'))\n",
    "                self.W[-l] = self.W[-l] - (alpha/self.m)*delta_w\n",
    "                self.B[-l] = self.B[-l] - (alpha/self.m)*delta_b\n",
    "                if self.ac_func == 'sigmoid' : \n",
    "                    delta = np.dot(self.W[-l].T, delta)*sigmoid_prime(z[-l-1])\n",
    "                elif self.ac_func == 'tanh' : \n",
    "                    delta = np.dot(self.W[-l].T, delta)*tanh_prime(z[-l-1])\n",
    "                elif self.ac_func == 'relu' : \n",
    "                    delta = np.dot(self.W[-l].T, delta)*ReLU_prime(z[-l-1])\n",
    "                elif self.ac_func == 'lrelu' : \n",
    "                    delta = np.dot(self.W[-l].T, delta)*lReLU_prime(z[-l-1])\n",
    "            if not i%interval :\n",
    "                aa = self.predict(self.X)\n",
    "                aa = aa > 0.5\n",
    "                self.acc = sum(sum(aa == self.y)) / self.m\n",
    "                cost_val = self._cost_func(a[-1])\n",
    "                self.cost.append(cost_val)\n",
    "            sys.stdout.write(f'\\rEpoch[{i}] : Cost = {cost_val:.2f} ; Acc = {(self.acc*100):.2f}% ; Time Taken = {(time.time()-start):.2f}s')\n",
    "        print('\\n')\n",
    "        return None\n",
    "    \n",
    "    def predict(self, X_test) : \n",
    "        if self.ac_func == 'sigmoid' : \n",
    "            a = sigmoid(np.dot(self.W[0], X_test) + self.B[0])\n",
    "            for l in range(1,len(self.layers)):\n",
    "                a = sigmoid(np.dot(self.W[l], a) + self.B[l])\n",
    "            return a\n",
    "        elif self.ac_func == 'tanh' : \n",
    "            a = tanh(np.dot(self.W[0], X_test) + self.B[0])\n",
    "            for l in range(1,len(self.layers)):\n",
    "                if l == (len(self.layers)-1) : \n",
    "                    a = sigmoid(np.dot(self.W[l], a) + self.B[l])\n",
    "                else : \n",
    "                    a = tanh(np.dot(self.W[l], a) + self.B[l])\n",
    "            return a\n",
    "        elif self.ac_func == 'relu' : \n",
    "            a = ReLU(np.dot(self.W[0], X_test) + self.B[0])\n",
    "            for l in range(1,len(self.layers)):\n",
    "                if l == (len(self.layers)-1) : \n",
    "                    a = sigmoid(np.dot(self.W[l], a) + self.B[l])\n",
    "                else : \n",
    "                    a = ReLU(np.dot(self.W[l], a) + self.B[l])\n",
    "            return a\n",
    "        elif self.ac_func == 'lrelu' : \n",
    "            a = lReLU(np.dot(self.W[0], X_test) + self.B[0])\n",
    "            for l in range(1,len(self.layers)):\n",
    "                if l == (len(self.layers)-1) : \n",
    "                    a = sigmoid(np.dot(self.W[l], a) + self.B[l])\n",
    "                else : \n",
    "                    a = lReLU(np.dot(self.W[l], a) + self.B[l])\n",
    "            return a\n",
    "            \n",
    "    \n",
    "    def _feedForward(self):\n",
    "        z = [];a = []\n",
    "        if self.ac_func == 'sigmoid' : \n",
    "            z.append(np.dot(self.W[0], self.X) + self.B[0])\n",
    "            a.append(sigmoid(z[0]))\n",
    "            for l in range(1,len(self.layers)):\n",
    "                z.append(np.dot(self.W[l], a[l-1]) + self.B[l])\n",
    "                a.append(sigmoid(z[l]))\n",
    "            return z,a\n",
    "        elif self.ac_func == 'tanh' :\n",
    "            z.append(np.dot(self.W[0], self.X) + self.B[0])\n",
    "            a.append(tanh(z[0]))\n",
    "            for l in range(1,len(self.layers)):\n",
    "                z.append(np.dot(self.W[l], a[l-1]) + self.B[l])\n",
    "                if l == (len(self.layers)-1) : \n",
    "                    a.append(sigmoid(z[l]))\n",
    "                else:\n",
    "                    a.append(tanh(z[l]))\n",
    "            a[-1] = sigmoid(z[-1])\n",
    "            return z,a\n",
    "        elif self.ac_func == 'relu' :\n",
    "            z.append(np.dot(self.W[0], self.X) + self.B[0])\n",
    "            a.append(ReLU(z[0]))\n",
    "            for l in range(1,len(self.layers)):\n",
    "                z.append(np.dot(self.W[l], a[l-1]) + self.B[l])\n",
    "                a.append(ReLU(z[l]))\n",
    "            a[-1] = sigmoid(z[-1])\n",
    "            return z,a\n",
    "        elif self.ac_func == 'lrelu' :\n",
    "            z.append(np.dot(self.W[0], self.X) + self.B[0])\n",
    "            a.append(lReLU(z[0]))\n",
    "            for l in range(1,len(self.layers)):\n",
    "                z.append(np.dot(self.W[l], a[l-1]) + self.B[l])\n",
    "                a.append(lReLU(z[l]))\n",
    "            a[-1] = sigmoid(z[-1])\n",
    "            return z,a\n",
    "    \n",
    "    def _cost_func(self, a):\n",
    "        return ( (-1/self.m)*np.sum(np.nan_to_num(self.y*np.log(a) + (1-self.y)*np.log(1-a))) )\n",
    "\n",
    "    def _cost_derivative(self, a) : \n",
    "        return a-self.y\n",
    "   \n",
    "    @property\n",
    "    def summary(self) :\n",
    "        return self.cost, self.acc, self.W,self.B\n",
    "    def __repr__(self) : \n",
    "        return f'<UNDER CONST>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[10000] : Cost = 0.25 ; Acc = 90.71% ; Time Taken = 58.75s\n",
      "\n",
      "Test set Accuracy ( Sigmoid ) : 88.33333333333333%\n"
     ]
    }
   ],
   "source": [
    "neural_net_sigmoid = NeuralNet([64,32,1], X_train, y_train, ac_func = 'sigmoid')\n",
    "neural_net_sigmoid.startTraining(10000, 0.005, 100)\n",
    "aa = neural_net_sigmoid.predict(X_test)\n",
    "aa = aa > 0.5\n",
    "acc = (sum(sum(aa == y_test)) / y_test.size)*100\n",
    "print(f'Test set Accuracy ( Sigmoid ) : {acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1000] : Cost = 0.16 ; Acc = 92.86% ; Time Taken = 5.17s\n",
      "\n",
      "Test set Accuracy ( Hyperbolic Tangent ) : 87.5%\n"
     ]
    }
   ],
   "source": [
    "neural_net_tanh = NeuralNet([64,32,1], X_train, y_train, ac_func = 'tanh')\n",
    "neural_net_tanh.startTraining(10000, 0.005, 100)\n",
    "aa = neural_net_tanh.predict(X_test)\n",
    "aa = aa > 0.5\n",
    "acc = (sum(sum(aa == y_test)) / y_test.size)*100\n",
    "print(f'Test set Accuracy ( Hyperbolic Tangent ) : {acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[10000] : Cost = 0.15 ; Acc = 92.14% ; Time Taken = 37.60s\n",
      "\n",
      "Test set Accuracy ( ReLU ) : 90.0%\n"
     ]
    }
   ],
   "source": [
    "neural_net_relu = NeuralNet([64,32,1], X_train, y_train, ac_func = 'relu')\n",
    "neural_net_relu.startTraining(10000, 0.002, 100)\n",
    "aa = neural_net_relu.predict(X_test)\n",
    "aa = aa > 0.5\n",
    "acc = (sum(sum(aa == y_test)) / y_test.size)*100\n",
    "print(f'Test set Accuracy ( ReLU ) : {acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[10000] : Cost = 0.20 ; Acc = 92.14% ; Time Taken = 52.61s\n",
      "\n",
      "Test set Accuracy ( Leaky ReLU ) : 88.33333333333333%\n"
     ]
    }
   ],
   "source": [
    "neural_net_lrelu = NeuralNet([64,32,1], X_train, y_train, ac_func = 'lrelu')\n",
    "neural_net_lrelu.startTraining(10000, 0.0015, 100)\n",
    "aa = neural_net_lrelu.predict(X_test)\n",
    "aa = aa > 0.5\n",
    "acc = (sum(sum(aa == y_test)) / y_test.size)*100\n",
    "print(f'Test set Accuracy ( Leaky ReLU ) : {acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sigmoid_summary = neural_net_sigmoid.summary\n",
    "tanh_summary = neural_net_tanh.summary\n",
    "relu_summary = neural_net_relu.summary\n",
    "lrelu_summary = neural_net_lrelu.summary\n",
    "plt.plot(range(len(sigmoid_summary[0])), sigmoid_summary[0], label='Sigmoid Cost')\n",
    "plt.plot(range(len(sigmoid_summary[0])), sigmoid_summary[0], label='Hyperbolic Tangent Cost')\n",
    "plt.plot(range(len(sigmoid_summary[0])), sigmoid_summary[0], label='ReLU Cost')\n",
    "plt.plot(range(len(sigmoid_summary[0])), sigmoid_summary[0], label='Leaky ReLU Cost')\n",
    "plt.legend()\n",
    "plt.title('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.5039 - acc: 0.7750\n",
      "Epoch 2/50\n",
      "280/280 [==============================] - 2s 6ms/step - loss: 0.3158 - acc: 0.8893\n",
      "Epoch 3/50\n",
      "280/280 [==============================] - 2s 6ms/step - loss: 0.2812 - acc: 0.8893\n",
      "Epoch 4/50\n",
      "280/280 [==============================] - 2s 6ms/step - loss: 0.2609 - acc: 0.9036\n",
      "Epoch 5/50\n",
      "280/280 [==============================] - 2s 6ms/step - loss: 0.2489 - acc: 0.8929\n",
      "Epoch 6/50\n",
      "280/280 [==============================] - 2s 6ms/step - loss: 0.2339 - acc: 0.8964A: 1s\n",
      "Epoch 7/50\n",
      "280/280 [==============================] - 2s 7ms/step - loss: 0.2335 - acc: 0.9071\n",
      "Epoch 8/50\n",
      "280/280 [==============================] - 1s 5ms/step - loss: 0.2255 - acc: 0.9071\n",
      "Epoch 9/50\n",
      "280/280 [==============================] - 1s 5ms/step - loss: 0.2253 - acc: 0.9071\n",
      "Epoch 10/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 0.2213 - acc: 0.9107\n",
      "Epoch 11/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 0.2222 - acc: 0.9071\n",
      "Epoch 12/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 0.2184 - acc: 0.9036\n",
      "Epoch 13/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2153 - acc: 0.9143\n",
      "Epoch 14/50\n",
      "280/280 [==============================] - 1s 4ms/step - loss: 0.2118 - acc: 0.9071TA: 0s - loss: 0.18\n",
      "Epoch 15/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2138 - acc: 0.9286\n",
      "Epoch 16/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2145 - acc: 0.9107\n",
      "Epoch 17/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2094 - acc: 0.9143\n",
      "Epoch 18/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2134 - acc: 0.9107\n",
      "Epoch 19/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2111 - acc: 0.9143\n",
      "Epoch 20/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2082 - acc: 0.9214\n",
      "Epoch 21/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.1988 - acc: 0.9214\n",
      "Epoch 22/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2113 - acc: 0.9214\n",
      "Epoch 23/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2042 - acc: 0.9179\n",
      "Epoch 24/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2104 - acc: 0.9214\n",
      "Epoch 25/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2053 - acc: 0.9143\n",
      "Epoch 26/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2011 - acc: 0.9179\n",
      "Epoch 27/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2082 - acc: 0.9179\n",
      "Epoch 28/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2032 - acc: 0.9179\n",
      "Epoch 29/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2031 - acc: 0.9143\n",
      "Epoch 30/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2023 - acc: 0.9214\n",
      "Epoch 31/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2040 - acc: 0.9179\n",
      "Epoch 32/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2029 - acc: 0.9143\n",
      "Epoch 33/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2025 - acc: 0.9143\n",
      "Epoch 34/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2066 - acc: 0.9250\n",
      "Epoch 35/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2052 - acc: 0.9179\n",
      "Epoch 36/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.1997 - acc: 0.9179\n",
      "Epoch 37/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2042 - acc: 0.9250\n",
      "Epoch 38/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2045 - acc: 0.9143\n",
      "Epoch 39/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2029 - acc: 0.9143\n",
      "Epoch 40/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2023 - acc: 0.9214\n",
      "Epoch 41/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.2013 - acc: 0.9143\n",
      "Epoch 42/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.1995 - acc: 0.9286\n",
      "Epoch 43/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.1967 - acc: 0.9214\n",
      "Epoch 44/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.1943 - acc: 0.9179\n",
      "Epoch 45/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.1964 - acc: 0.9250\n",
      "Epoch 46/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.1935 - acc: 0.9179\n",
      "Epoch 47/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.1919 - acc: 0.9250\n",
      "Epoch 48/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.1954 - acc: 0.9250\n",
      "Epoch 49/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.1944 - acc: 0.9250\n",
      "Epoch 50/50\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.1919 - acc: 0.9179\n",
      "Test set Accuracy : 89.16666666666667%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "X_train, X_test, X_CV = X_train.T, X_test.T, X_CV.T\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(input_dim=4, units = 64, kernel_initializer=\"uniform\", activation=\"relu\"))\n",
    "classifier.add(Dense(units = 32, kernel_initializer = \"uniform\", activation=\"relu\"))\n",
    "# classifier.add(Dense(units = 16, kernel_initializer = \"uniform\", activation=\"tanh\"))\n",
    "classifier.add(Dense(units = 1, kernel_initializer = \"uniform\", activation = \"sigmoid\"))\n",
    "classifier.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "classifier.fit(X_train, y_train, batch_size = 1, epochs = 50)\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = 1*(y_pred > 0.5)\n",
    "test_acc = sum(sum(y_pred.T == y_test)) / y_test.size\n",
    "print(f\"Test set Accuracy : {test_acc*100}%\")\n",
    "X_train, X_test, X_CV = X_train.T, X_test.T, X_CV.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
